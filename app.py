import streamlit as st
import openai
from dotenv import load_dotenv
import os
import time

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìš´ì„¸ ì±„íŒ… ì„œë¹„ìŠ¤",
    page_icon="ğŸ”®",
    layout="wide"
)

# íƒ€ì´í‹€ê³¼ ì„¤ëª…
st.title("ğŸ”® ìš´ì„¸ ì±„íŒ… ì„œë¹„ìŠ¤")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ì´ˆê¸° ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({
        "role": "assistant",
        "content": "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ìš´ì„¸ë¥¼ ë´ë“œë¦´ê¹Œìš”?"
    })

# ìš´ì„¸ ìƒë‹´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ìš´ì„¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ìƒë…„ì›”ì¼ê³¼ ì‹œê°„ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì£¼íŒ”ì, ìš´ì„¸, ê·¸ë¦¬ê³  ë¯¸ë˜ì— ëŒ€í•œ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê¸ì •ì ì´ë©°, êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
ë‹¨, ì ˆëŒ€ì ìœ¼ë¡œ ë¯¿ì„ ìˆ˜ ì—†ëŠ” ì˜ˆì¸¡ì€ í”¼í•˜ê³ , í˜„ì‹¤ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

# ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ìš´ì„¸ ìœ í˜• ì„ íƒ ë²„íŠ¼ë“¤
if len(st.session_state.messages) == 1:  # ì´ˆê¸° ë©”ì‹œì§€ë§Œ ìˆì„ ë•Œë§Œ ì„ íƒì§€ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("âœ¨ ë³„ìë¦¬ ìš´ì„¸"):
            st.session_state.messages.append({"role": "user", "content": "ë³„ìë¦¬ ìš´ì„¸ë¥¼ ë³´ê³  ì‹¶ì–´ìš”."})
            st.experimental_rerun()
    with col2:
        if st.button("ğŸ‹ ì‚¬ì£¼íŒ”ì"):
            st.session_state.messages.append({"role": "user", "content": "ì‚¬ì£¼íŒ”ìë¥¼ ë³´ê³  ì‹¶ì–´ìš”."})
            st.experimental_rerun()
    with col3:
        if st.button("ğŸ¯ íƒ€ë¡œì¹´ë“œ"):
            st.session_state.messages.append({"role": "user", "content": "íƒ€ë¡œì¹´ë“œë¡œ ìš´ì„¸ë¥¼ ë³´ê³  ì‹¶ì–´ìš”."})
            st.experimental_rerun()

# ì‚¬ìš©ì ì…ë ¥
user_input = st.text_input("ê¶ê¸ˆí•˜ì‹  ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:", key="user_input")

# ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ê²½ìš° ì²˜ë¦¬
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # ë¡œë”© ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("...")
        
        # AI ì‘ë‹µ ìƒì„±
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    *[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            ai_response = response.choices[0].message.content
            
            # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜
            for i in range(3):
                message_placeholder.markdown("..." * (i + 1))
                time.sleep(0.5)
            
            # ìµœì¢… ì‘ë‹µ í‘œì‹œ
            message_placeholder.markdown(ai_response)
            
            # AI ì‘ë‹µ ì¶”ê°€
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
            
        except Exception as e:
            st.error(f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ì‚¬ì´ë“œë°”ì— ì¶”ê°€ ì •ë³´
with st.sidebar:
    st.header("ğŸ“ ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. ì›í•˜ëŠ” ìš´ì„¸ ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”
    2. ìƒë…„ì›”ì¼ê³¼ ì‹œê°„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”
    3. ê¶ê¸ˆí•˜ì‹  ì ì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”
    4. AIê°€ ìƒì„¸í•œ ìš´ì„¸ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤
    """)
    
    st.header("âš ï¸ ì£¼ì˜ì‚¬í•­")
    st.markdown("""
    - ì´ ì„œë¹„ìŠ¤ëŠ” ì¬ë¯¸ë¡œë§Œ ì°¸ê³ í•´ì£¼ì„¸ìš”
    - ì¤‘ìš”í•œ ì¸ìƒ ê²°ì •ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
    - ê°œì¸ì •ë³´ëŠ” ì•ˆì „í•˜ê²Œ ë³´í˜¸ë©ë‹ˆë‹¤
    """) 